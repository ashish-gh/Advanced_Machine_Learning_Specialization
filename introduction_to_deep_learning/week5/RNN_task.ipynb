{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "RNN-task.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMiX02fwAhoZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5a904c09-17ae-4af3-bcd9-84cc3aaf2c67"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-04 10:06:13--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3636 (3.6K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-03-04 10:06:18 (53.6 MB/s) - ‘setup_google_colab.py’ saved [3636/3636]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow-WQIkCAlHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "setup_google_colab.setup_week5()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8QwYl77AP9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set tf 1.x for colab\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsu6Tq4zAP9u",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "1QzkMV9bAP9w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c14533c8-f077-4802-ab37-22b2cbd9bcba"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqJnjazbAP93",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "-SA-xVhKAP95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "suuhe0FxAP9_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "5f8f54ef-4fac-4fb1-fc4b-fc28433070a0"
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "5k3SP3tOAP-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "4e8d21b0-9d67-4d10-9384-a2b5879eaf77"
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ9/MLCMOfTOzjPx/p/4cUF1Gcl0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEqNlS70AP-M",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "oJThvQwKAP-P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c1be2c88-366c-41af-838a-df5a5ed80de7"
      },
      "source": [
        "\n",
        "tokens = set(''.join(names)) ### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "tokens.add(pad_token)\n",
        "print(tokens)\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'b', 'e', 'r', '-', 's', 'X', 'm', 'T', 'c', 'K', 'g', 'V', 'A', 'q', 'J', 'Y', 'W', 'k', 'P', 'z', 'F', 'R', 'f', 'E', 'h', 'w', 'j', 'N', 'Q', 'a', 'I', ' ', 'G', 'Z', 'v', 'p', \"'\", 'O', 'u', 'y', 'o', 'H', 'x', 'D', 'L', 'U', 'M', 'd', 'l', 'n', 'B', 'S', 'i', 't', 'C', '#'}\n",
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir3h6gKLAP-X",
        "colab_type": "text"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "k_AUAKQdAP-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "463c4c84-3059-4062-c2b1-5a0650f3f84c"
      },
      "source": [
        "token_to_id = {s : i for i, s in enumerate(tokens)} ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
        "print(token_to_id)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'b': 0, 'e': 1, 'r': 2, '-': 3, 's': 4, 'X': 5, 'm': 6, 'T': 7, 'c': 8, 'K': 9, 'g': 10, 'V': 11, 'A': 12, 'q': 13, 'J': 14, 'Y': 15, 'W': 16, 'k': 17, 'P': 18, 'z': 19, 'F': 20, 'R': 21, 'f': 22, 'E': 23, 'h': 24, 'w': 25, 'j': 26, 'N': 27, 'Q': 28, 'a': 29, 'I': 30, ' ': 31, 'G': 32, 'Z': 33, 'v': 34, 'p': 35, \"'\": 36, 'O': 37, 'u': 38, 'y': 39, 'o': 40, 'H': 41, 'x': 42, 'D': 43, 'L': 44, 'U': 45, 'M': 46, 'd': 47, 'l': 48, 'n': 49, 'B': 50, 'S': 51, 'i': 52, 't': 53, 'C': 54, '#': 55}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "Q6f7nblyAP-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "vGGVLgpQAP-j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "31a78634-a03d-4da3-b108-26f57e61d0e7"
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[31 12  0 29 10 29  1 48 55]\n",
            " [31 32 48 40  2 39 55 55 55]\n",
            " [31 18  2 52  4  4 52  1 55]\n",
            " [31 32 52 40 34 29 49 49  1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv5hlupyAP-p",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/ashish-gh/Advanced_Machine_Learning_Specialization/blob/master/introduction_to_deep_learning/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "zmUCCvsvAP-r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "481091f0-2624-4cea-ac0d-d0193d65562c"
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:79: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:82: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:84: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:77: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "kXBmndh_AP-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation='tanh') ### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation='softmax') ### YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3Z7LTWuAP-0",
        "colab_type": "text"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/ashish-gh/Advanced_Machine_Learning_Specialization/blob/master/introduction_to_deep_learning/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "EHuuCkAWAP-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = concatenate([x_t_emb, h_t]) ### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h) ### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next) ### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwgyqVnbAP-9",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "fXJkQOcNAP-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "eb24fcb4-cc42-4eac-bfc3-a9910b40d0cd"
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3535: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj6wWYBpAP_G",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "jjd91JpcAP_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DEdch42AP_R",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "bflEcisJAP_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss = -tf.reduce_mean(answers_matrix * tf.log(predictions_matrix)) ### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7ycElwCAP_Y",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "LBrWpZPbAP_a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "14133860-d741-4096-8abe-1846456fd6ae"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKaUcTgO9Uko53P8DMMHsFVT8amQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT-IuzXJAP_g",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "yTCe71AyAP_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "eXP8v18dAP_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "qCQCwm9GAP_u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "4b186a65-ade7-4cb3-eeea-da993ce7aae6"
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Serrieta\n",
            " Hics\n",
            " Enii\n",
            " Naziu\n",
            " Asie\n",
            " Carehene\n",
            " Tabna\n",
            " Corli\n",
            " Sharam\n",
            " Vavy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "puWaUu47AP_y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e70a3ad4-16a0-44e6-a33b-b99d2242ce46"
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpian\n",
            " Trumpy\n",
            " Trumph\n",
            " Trumpa\n",
            " Trump\n",
            " Trumpmon\n",
            " Trump\n",
            " Trumpudo\n",
            " Trumpa\n",
            " Trumpa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXONG2b7AP_3",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "w8yZ5zaXAP_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"yOYlCJtCT9uW1zu1\"\n",
        "COURSERA_EMAIL = \"ashish.gh123@gmail.com\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "-m7wYEGpAP_9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "caeeed1b-6a0f-47d8-b224-2e950970b7a4"
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmBb7M82AQAD",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "vaRyGY3XAQAE",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "6C3crAzVAQAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoHPYG6MAQAK",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "BK8fBinkAQAN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "f692ccf0-22f4-46ae-fb33-835f9c26e53e"
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell\t"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "7THbhldyAQAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}